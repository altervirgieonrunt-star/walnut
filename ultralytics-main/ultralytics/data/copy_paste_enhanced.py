# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
"""
Enhanced Copy-Paste Data Augmentation for Egg Segmentation
å¢å¼ºç‰ˆå¤åˆ¶ç²˜è´´æ•°æ®å¢å¼º - ä¸“ä¸ºé¸­è›‹åˆ†å‰²ä»»åŠ¡è®¾è®¡

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å»ºç«‹å®ä¾‹æ± ï¼ˆInstance Poolï¼‰- å­˜å‚¨æ‰€æœ‰å¯å¤åˆ¶çš„eggå’Œbarrierå®ä¾‹
2. éšæœºå¤åˆ¶ç²˜è´´ - ä»å®ä¾‹æ± ä¸­éšæœºé€‰æ‹©å®ä¾‹ç²˜è´´åˆ°ç›®æ ‡å›¾åƒ
3. æ™ºèƒ½æ©ç å¤„ç† - å¤„ç†é®æŒ¡å…³ç³»ï¼Œæ›´æ–°æˆ–åˆ é™¤è¢«é®æŒ¡çš„æ©ç 
4. è¾¹ç•Œç¾½åŒ– - å¯é€‰çš„è¾¹ç•Œå¹³æ»‘å¤„ç†

å‚è€ƒè®ºæ–‡ï¼š
Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation
https://arxiv.org/abs/2012.07177
"""

from __future__ import annotations

import random
from copy import deepcopy
from pathlib import Path
from typing import Any, List, Dict, Tuple

import cv2
import numpy as np
from ultralytics.utils import LOGGER
from ultralytics.utils.instance import Instances


class InstancePool:
    """
    å®ä¾‹æ±  - å­˜å‚¨æ‰€æœ‰å¯ç”¨äºCopy-Pasteçš„ç›®æ ‡å®ä¾‹
    
    æ¯ä¸ªå®ä¾‹åŒ…å«ï¼š
    - image: æŠ å‡ºçš„ç›®æ ‡å›¾åƒï¼ˆå¸¦é€æ˜é€šé“æˆ–åŸå§‹RGBï¼‰
    - mask: äºŒå€¼åŒ–æ©ç 
    - class_id: ç±»åˆ«IDï¼ˆ0=egg, 1=barrierç­‰ï¼‰
    - bbox: è¾¹ç•Œæ¡† [x1, y1, x2, y2]
    """
    
    def __init__(self, max_size: int = 1000):
        """
        åˆå§‹åŒ–å®ä¾‹æ± 
        
        Args:
            max_size: å®ä¾‹æ± æœ€å¤§å®¹é‡ï¼ˆé¿å…å†…å­˜æº¢å‡ºï¼‰
        """
        self.instances: List[Dict[str, Any]] = []
        self.max_size = max_size
        self.egg_instances = []  # ä¸“é—¨å­˜å‚¨eggå®ä¾‹
        self.barrier_instances = []  # ä¸“é—¨å­˜å‚¨barrierå®ä¾‹
        
    def add_instance(self, image: np.ndarray, mask: np.ndarray, class_id: int, bbox: np.ndarray = None):
        """
        æ·»åŠ ä¸€ä¸ªå®ä¾‹åˆ°æ± ä¸­
        
        Args:
            image: åŸå§‹å›¾åƒ
            mask: å®ä¾‹æ©ç ï¼ˆäºŒå€¼åŒ–æˆ–å¤šè¾¹å½¢æ ¼å¼ï¼‰
            class_id: ç±»åˆ«ID
            bbox: è¾¹ç•Œæ¡†ï¼ˆå¯é€‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä»maskè®¡ç®—ï¼‰
        """
        if len(self.instances) >= self.max_size:
            # éšæœºåˆ é™¤ä¸€ä¸ªæ—§å®ä¾‹ï¼ˆFIFOç­–ç•¥ï¼‰
            self.instances.pop(0)
            
        # å¦‚æœmaskæ˜¯å¤šè¾¹å½¢æ ¼å¼ï¼Œè½¬æ¢ä¸ºäºŒå€¼æ©ç 
        if mask.dtype != bool and mask.max() <= 1:
            mask = mask.astype(bool)
        elif mask.dtype != bool:
            mask = mask > 0
            
        # è®¡ç®—è¾¹ç•Œæ¡†
        if bbox is None:
            bbox = self._mask_to_bbox(mask)
            
        # è£å‰ªå‡ºå®ä¾‹åŒºåŸŸ
        x1, y1, x2, y2 = bbox.astype(int)
        if x2 <= x1 or y2 <= y1:
            return  # æ— æ•ˆbbox
            
        # ç¡®ä¿è¾¹ç•Œåœ¨å›¾åƒèŒƒå›´å†…
        h, w = image.shape[:2]
        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(w, x2), min(h, y2)
        
        cropped_img = image[y1:y2, x1:x2].copy()
        cropped_mask = mask[y1:y2, x1:x2].copy()
        
        instance = {
            'image': cropped_img,
            'mask': cropped_mask,
            'class_id': class_id,
            'bbox': bbox,
            'original_size': (y2 - y1, x2 - x1)  # H, W
        }
        
        self.instances.append(instance)
        
        # åŒæ—¶æ·»åŠ åˆ°åˆ†ç±»åˆ—è¡¨
        if class_id == 0:  # egg
            self.egg_instances.append(instance)
        else:  # barrier
            self.barrier_instances.append(instance)
    
    def get_random_instance(self, prefer_class: int = None, balance_classes: bool = True) -> Dict[str, Any]:
        """
        éšæœºè·å–ä¸€ä¸ªå®ä¾‹ï¼ˆæ”¯æŒç±»åˆ«å¹³è¡¡é‡‡æ ·ï¼‰
        
        Args:
            prefer_class: ä¼˜å…ˆé€‰æ‹©çš„ç±»åˆ«ï¼ˆNoneè¡¨ç¤ºéšæœºï¼‰
            balance_classes: æ˜¯å¦å¹³è¡¡ç±»åˆ«é‡‡æ ·ï¼ˆä¼˜å…ˆé‡‡æ ·å°‘æ•°ç±»ï¼‰
            
        Returns:
            å®ä¾‹å­—å…¸çš„æ·±æ‹·è´
        """
        if len(self.instances) == 0:
            return None
        
        # ç±»åˆ«å¹³è¡¡ç­–ç•¥ï¼šä¼˜å…ˆé‡‡æ ·å°‘æ•°ç±»
        if balance_classes and prefer_class is None:
            n_egg = len(self.egg_instances)
            n_barrier = len(self.barrier_instances)
            
            if n_egg > 0 and n_barrier > 0:
                # è®¡ç®—é‡‡æ ·æƒé‡ï¼šå°‘æ•°ç±»æƒé‡æ›´é«˜
                total = n_egg + n_barrier
                # å¦‚æœbarrierå¾ˆå°‘ï¼Œç»™å®ƒæ›´é«˜çš„é‡‡æ ·æ¦‚ç‡
                barrier_prob = max(0.3, 1.0 - n_barrier / total)  # è‡³å°‘30%æ¦‚ç‡é‡‡æ ·barrier
                
                if random.random() < barrier_prob and n_barrier > 0:
                    prefer_class = 1  # barrier
                else:
                    prefer_class = 0  # egg
            elif n_barrier > 0:
                prefer_class = 1
            else:
                prefer_class = 0
        
        # æ ¹æ®prefer_classé€‰æ‹©æ± 
        if prefer_class is not None:
            pool = self.egg_instances if prefer_class == 0 else self.barrier_instances
            if len(pool) == 0:
                pool = self.instances
        else:
            pool = self.instances
            
        return deepcopy(random.choice(pool))
    
    def build_from_dataset(self, dataset, max_images: int = 200, verbose: bool = True, sample_strategy: str = 'uniform'):
        """
        ä»æ•°æ®é›†æ„å»ºå®ä¾‹æ± 
        
        Args:
            dataset: YOLOæ•°æ®é›†å¯¹è±¡
            max_images: æœ€å¤šä½¿ç”¨å¤šå°‘å¼ å›¾åƒæ„å»ºæ± 
            verbose: æ˜¯å¦æ‰“å°è¿›åº¦
            sample_strategy: é‡‡æ ·ç­–ç•¥ ('sequential'=é¡ºåº, 'uniform'=å‡åŒ€åˆ†å¸ƒ, 'random'=éšæœº)
        """
        total_images = len(dataset)
        n_images = min(total_images, max_images)
        n_instances = 0
        
        # é€‰æ‹©å›¾åƒç´¢å¼•
        if sample_strategy == 'uniform':
            # å‡åŒ€åˆ†å¸ƒé‡‡æ ·ï¼ˆç¡®ä¿è¦†ç›–æ•´ä¸ªæ•°æ®é›†ï¼‰
            indices = np.linspace(0, total_images-1, n_images, dtype=int)
        elif sample_strategy == 'random':
            # éšæœºé‡‡æ ·
            indices = np.random.choice(total_images, n_images, replace=False)
        else:  # sequential
            indices = range(n_images)
        
        if verbose:
            LOGGER.info(f"Building instance pool from {n_images} images (strategy={sample_strategy})...")
        
        for i in indices:
            try:
                # è·å–å›¾åƒå’Œæ ‡ç­¾
                data = dataset.get_image_and_label(i)
                img = data['img']
                instances = data.get('instances', None)
                
                if instances is None or len(instances) == 0:
                    continue
                    
                # æå–æ¯ä¸ªå®ä¾‹
                h, w = img.shape[:2]
                
                # ç¡®ä¿instancesæœ‰segments
                if not hasattr(instances, 'segments') or len(instances.segments) == 0:
                    continue
                
                segments = instances.segments
                
                # æ­£ç¡®æå–ç±»åˆ«ä¿¡æ¯ - ç±»åˆ«åœ¨data['cls']ä¸­ï¼Œè€Œä¸æ˜¯instances.cls
                cls_data = data.get('cls', None)
                if cls_data is not None:
                    # å¤„ç†ä¸åŒçš„clsæ ¼å¼
                    if hasattr(cls_data, 'cpu'):  # torch tensor
                        cls_data = cls_data.cpu().numpy()
                    if hasattr(cls_data, 'flatten'):  # numpy array
                        cls_data = cls_data.flatten()
                    classes = cls_data
                else:
                    # å¦‚æœdataä¸­ä¹Ÿæ²¡æœ‰clsï¼Œå°è¯•ä»instancesä¸­è·å–
                    if hasattr(instances, 'cls'):
                        cls_data = instances.cls
                        if hasattr(cls_data, 'cpu'):
                            cls_data = cls_data.cpu().numpy()
                        if hasattr(cls_data, 'flatten'):
                            cls_data = cls_data.flatten()
                        classes = cls_data
                    else:
                        classes = np.zeros(len(segments))
                
                for j, seg in enumerate(segments):
                    # å°†segmentè½¬æ¢ä¸ºmask
                    # æ³¨æ„ï¼šsegmentsæ˜¯å½’ä¸€åŒ–åæ ‡(0-1)ï¼Œéœ€è¦è½¬æ¢ä¸ºåƒç´ åæ ‡
                    mask = np.zeros((h, w), dtype=np.uint8)
                    
                    # è½¬æ¢å½’ä¸€åŒ–åæ ‡åˆ°åƒç´ åæ ‡
                    seg_pixels = seg.copy()
                    seg_pixels[:, 0] *= w  # xåæ ‡
                    seg_pixels[:, 1] *= h  # yåæ ‡
                    seg_int = seg_pixels.astype(np.int32)
                    
                    if len(seg_int) > 0:
                        cv2.fillPoly(mask, [seg_int], 1)
                        
                        # æ·»åŠ åˆ°å®ä¾‹æ± 
                        class_id = int(classes[j]) if j < len(classes) else 0
                        self.add_instance(img, mask.astype(bool), class_id)
                        n_instances += 1
                        
                        # è°ƒè¯•ï¼šè®°å½•barrierå®ä¾‹
                        if class_id == 1 and verbose and len(self.barrier_instances) <= 5:
                            LOGGER.info(f"  Found barrier in image {i}: class_id={class_id}")
                        
            except Exception as e:
                if verbose:
                    LOGGER.warning(f"Error processing image {i}: {e}")
                continue
        
        if verbose:
            n_egg = len(self.egg_instances)
            n_barrier = len(self.barrier_instances)
            LOGGER.info(f"Instance pool built: {n_instances} instances total")
            LOGGER.info(f"  - Eggs: {n_egg} ({100*n_egg/max(n_instances,1):.1f}%)")
            LOGGER.info(f"  - Barriers: {n_barrier} ({100*n_barrier/max(n_instances,1):.1f}%)")
            
            # ç±»åˆ«ä¸å¹³è¡¡è­¦å‘Š
            if n_barrier == 0 and n_egg > 0:
                LOGGER.warning("âš ï¸  No barrier instances found! Only egg instances will be pasted.")
                LOGGER.warning("   Consider increasing cp_pool_images to find more barrier examples.")
            elif n_barrier > 0 and n_egg / max(n_barrier, 1) > 10:
                LOGGER.warning(f"âš ï¸  Class imbalance detected: {n_egg/max(n_barrier,1):.1f}:1 (egg:barrier)")
                LOGGER.warning("   Using balanced sampling to prefer minority class (barrier).")
    
    @staticmethod
    def _mask_to_bbox(mask: np.ndarray) -> np.ndarray:
        """ä»maskè®¡ç®—è¾¹ç•Œæ¡†"""
        rows = np.any(mask, axis=1)
        cols = np.any(mask, axis=0)
        if not rows.any() or not cols.any():
            return np.array([0, 0, 1, 1])
        y1, y2 = np.where(rows)[0][[0, -1]]
        x1, x2 = np.where(cols)[0][[0, -1]]
        return np.array([x1, y1, x2 + 1, y2 + 1])
    
    def __len__(self):
        return len(self.instances)


class CopyPasteEnhanced:
    """
    å¢å¼ºç‰ˆCopy-Pasteæ•°æ®å¢å¼º
    
    ç‰¹ç‚¹ï¼š
    1. ä½¿ç”¨å®ä¾‹æ± å­˜å‚¨å¯å¤åˆ¶çš„å®ä¾‹
    2. æ™ºèƒ½å¤„ç†æ©ç é®æŒ¡å…³ç³»
    3. åˆ é™¤å®Œå…¨è¢«é®æŒ¡çš„æ©ç 
    4. æ›´æ–°éƒ¨åˆ†è¢«é®æŒ¡çš„æ©ç 
    5. å¯é€‰çš„è¾¹ç•Œç¾½åŒ–æ•ˆæœ
    """
    
    def __init__(
        self,
        instance_pool: InstancePool = None,
        p: float = 0.5,
        n_paste: Tuple[int, int] = (1, 5),
        scale_range: Tuple[float, float] = (0.5, 1.5),
        min_area_threshold: int = 100,
        blend_edges: bool = False,
        blend_kernel: int = 5,
        balance_classes: bool = True  # æ–°å¢ï¼šæ˜¯å¦å¹³è¡¡ç±»åˆ«
    ):
        """
        åˆå§‹åŒ–Copy-Pasteå¢å¼ºå™¨
        
        Args:
            instance_pool: å®ä¾‹æ± å¯¹è±¡
            p: åº”ç”¨å¢å¼ºçš„æ¦‚ç‡
            n_paste: æ¯æ¬¡ç²˜è´´çš„å®ä¾‹æ•°é‡èŒƒå›´ (min, max)
            scale_range: ç²˜è´´å®ä¾‹çš„ç¼©æ”¾èŒƒå›´
            min_area_threshold: æœ€å°é¢ç§¯é˜ˆå€¼ï¼ˆå°äºæ­¤å€¼çš„maskä¼šè¢«åˆ é™¤ï¼‰
            blend_edges: æ˜¯å¦å¯¹è¾¹ç¼˜è¿›è¡Œç¾½åŒ–
            blend_kernel: ç¾½åŒ–æ ¸å¤§å°
        """
        self.instance_pool = instance_pool if instance_pool is not None else InstancePool()
        self.p = p
        self.n_paste = n_paste
        self.scale_range = scale_range
        self.min_area_threshold = min_area_threshold
        self.blend_edges = blend_edges
        self.blend_kernel = blend_kernel
        self.balance_classes = balance_classes
        
    def __call__(self, labels: dict[str, Any]) -> dict[str, Any]:
        """
        å¯¹æ ‡ç­¾æ•°æ®åº”ç”¨Copy-Pasteå¢å¼º
        
        Args:
            labels: YOLOæ ‡ç­¾å­—å…¸ï¼ŒåŒ…å« 'img', 'instances' ç­‰
            
        Returns:
            å¢å¼ºåçš„æ ‡ç­¾å­—å…¸
        """
        # æ£€æŸ¥æ˜¯å¦åº”ç”¨å¢å¼º
        if random.random() > self.p:
            return labels
        
        # æ£€æŸ¥å®ä¾‹æ± æ˜¯å¦ä¸ºç©º
        if len(self.instance_pool) == 0:
            return labels
        
        # æ£€æŸ¥æ˜¯å¦æœ‰segments
        if 'instances' not in labels or len(labels['instances']) == 0:
            return labels
            
        instances = labels['instances']
        if not hasattr(instances, 'segments') or len(instances.segments) == 0:
            return labels
        
        # æ‰§è¡ŒCopy-Paste
        return self._copy_paste_transform(labels)
    
    def _copy_paste_transform(self, labels: dict[str, Any]) -> dict[str, Any]:
        """
        æ‰§è¡ŒCopy-Pasteå˜æ¢çš„æ ¸å¿ƒé€»è¾‘
        """
        img = labels['img'].copy()
        h, w = img.shape[:2]
        instances = labels['instances']
        
        # å°†å½“å‰å®ä¾‹è½¬æ¢ä¸ºmaskåˆ—è¡¨ + ä¿å­˜å¯¹åº”çš„ç±»åˆ«ï¼ˆä¸€å¯¹ä¸€ï¼‰
        current_masks = self._instances_to_masks(instances, h, w)
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šclsåœ¨labels['cls']ä¸­ï¼Œä¸åœ¨instancesä¸­ï¼
        # å¿…é¡»ä»labelsä¸­è·å–ï¼Œè€Œä¸æ˜¯ä»instancesä¸­
        if 'cls' in labels:
            current_classes = labels['cls']
            # å¤„ç†ä¸åŒçš„æ•°æ®ç±»å‹
            if hasattr(current_classes, 'cpu'):
                current_classes = current_classes.cpu().numpy()
            if hasattr(current_classes, 'flatten'):
                current_classes = current_classes.flatten()
        else:
            # å¦‚æœlabelsä¸­ä¹Ÿæ²¡æœ‰clsï¼Œå°è¯•ä»instancesè·å–ï¼ˆå‘åå…¼å®¹ï¼‰
            if hasattr(instances, 'cls'):
                current_classes = instances.cls.cpu().numpy() if hasattr(instances.cls, 'cpu') else instances.cls
            else:
                # æœ€åçš„fallbackï¼šè®¾ä¸º0ï¼ˆä½†è¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼‰
                current_classes = np.zeros(len(instances))
        
        # âš ï¸ å…³é”®ï¼šå°†maskså’Œclassesæˆå¯¹å­˜å‚¨ï¼Œç¡®ä¿åŒæ­¥åˆ é™¤
        current_items = list(zip(current_masks, current_classes))
        
        # ç¡®å®šè¦ç²˜è´´çš„å®ä¾‹æ•°é‡
        n_to_paste = random.randint(self.n_paste[0], self.n_paste[1])
        
        # å­˜å‚¨æ–°å¢çš„items (mask, class_id)
        new_items = []
        
        for _ in range(n_to_paste):
            # ä»å®ä¾‹æ± ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªå®ä¾‹ï¼ˆä½¿ç”¨ç±»åˆ«å¹³è¡¡ç­–ç•¥ï¼‰
            source_instance = self.instance_pool.get_random_instance(balance_classes=self.balance_classes)
            if source_instance is None:
                continue
            
            # æ ¹æ®ç±»åˆ«é€‰æ‹©ä¸åŒçš„ç¼©æ”¾ç­–ç•¥
            # egg(class 0): ä¸ç¼©æ”¾æˆ–è½»å¾®ç¼©æ”¾ï¼ˆæœ¬èº«å¾ˆå°ï¼‰
            # barrier(class 1): å¯ä»¥å¤§å¹…ç¼©æ”¾ï¼ˆæœ¬èº«å¾ˆå¤§ï¼‰
            class_id = source_instance['class_id']
            if class_id == 0:  # egg
                scale_range_for_class = (1.0, 1.0)  # ä¸ç¼©æ”¾
            elif class_id == 1:  # barrier
                scale_range_for_class = (0.5, 1.5)  # å¤§å¹…ç¼©æ”¾ï¼ˆå¯ä»¥ç¼©å°ï¼‰
            else:
                scale_range_for_class = self.scale_range  # å…¶ä»–ç±»åˆ«ä½¿ç”¨é»˜è®¤
            
            # åº”ç”¨éšæœºå˜æ¢ï¼ˆç¼©æ”¾ã€æ—‹è½¬ç­‰ï¼‰
            transformed = self._transform_instance(source_instance, scale_range_for_class)
            
            # é€‰æ‹©ç²˜è´´ä½ç½®
            paste_x, paste_y = self._get_paste_position(transformed, h, w)
            
            # åˆ›å»ºç²˜è´´maskï¼ˆåœ¨ç›®æ ‡å›¾åƒåæ ‡ç³»ä¸­ï¼‰
            paste_mask = np.zeros((h, w), dtype=bool)
            inst_h, inst_w = transformed['mask'].shape
            
            # ç¡®ä¿ä¸è¶…å‡ºè¾¹ç•Œ
            y_end = min(paste_y + inst_h, h)
            x_end = min(paste_x + inst_w, w)
            inst_h_actual = y_end - paste_y
            inst_w_actual = x_end - paste_x
            
            if inst_h_actual <= 0 or inst_w_actual <= 0:
                continue
                
            paste_mask[paste_y:y_end, paste_x:x_end] = transformed['mask'][:inst_h_actual, :inst_w_actual]
            
            # ç²˜è´´å›¾åƒå†…å®¹
            if self.blend_edges:
                # è¾¹ç¼˜ç¾½åŒ–
                img = self._blend_paste(img, transformed['image'], paste_mask, paste_x, paste_y)
            else:
                # ç›´æ¥æ›¿æ¢
                img[paste_mask] = transformed['image'][:inst_h_actual, :inst_w_actual][
                    transformed['mask'][:inst_h_actual, :inst_w_actual]
                ]
            
            # ğŸ”§ ä¿®å¤BUGï¼šå¤„ç†é®æŒ¡æ—¶åŒæ­¥æ›´æ–°maskså’Œclasses
            current_items = self._handle_occlusion_with_classes(current_items, paste_mask)
            
            # æ·»åŠ æ–°item (mask, class_id)
            new_items.append((paste_mask, transformed['class_id']))
        
        # åˆå¹¶currentå’Œnew items
        all_items = current_items + new_items
        
        # åˆ†ç¦»maskså’Œclasses
        all_masks = [item[0] for item in all_items]
        all_classes = np.array([item[1] for item in all_items]) if all_items else np.array([])
        
        # è¿‡æ»¤æ‰é¢ç§¯å¤ªå°çš„masks
        valid_indices = []
        for i, mask in enumerate(all_masks):
            if mask.sum() >= self.min_area_threshold:
                valid_indices.append(i)
        
        all_masks = [all_masks[i] for i in valid_indices]
        all_classes = all_classes[valid_indices] if len(valid_indices) > 0 else np.array([])
        
        # æ›´æ–°labels
        labels['img'] = img
        
        if len(all_masks) > 0:
            # å°†masksè½¬æ¢å›instancesæ ¼å¼
            new_instances = self._masks_to_instances(all_masks, all_classes, h, w)
            labels['instances'] = new_instances
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šä½¿ç”¨æ’åºåçš„clsï¼ˆä»instancesä¸­è·å–ï¼‰ï¼Œè€Œä¸æ˜¯æœªæ’åºçš„all_classes
            labels['cls'] = new_instances.cls.reshape(-1, 1)
        else:
            # æ²¡æœ‰æœ‰æ•ˆå®ä¾‹ - å¿…é¡»è¿”å›æ­£ç¡®æ ¼å¼çš„ç©ºnumpyæ•°ç»„
            labels['instances'] = Instances(
                bboxes=np.empty((0, 4)),
                segments=np.zeros((0, 1000, 2), dtype=np.float32),  # ç©ºçš„3Dæ•°ç»„ï¼Œä¸æ˜¯åˆ—è¡¨
                bbox_format='xyxy',
                normalized=False
            )
            labels['cls'] = np.empty((0, 1))
        
        return labels
    
    def _instances_to_masks(self, instances, h: int, w: int) -> List[np.ndarray]:
        """å°†Instanceså¯¹è±¡è½¬æ¢ä¸ºmaskåˆ—è¡¨"""
        masks = []
        segments = instances.segments
        
        for seg in segments:
            mask = np.zeros((h, w), dtype=np.uint8)
            seg_int = seg.astype(np.int32)
            if len(seg_int) > 0:
                cv2.fillPoly(mask, [seg_int], 1)
                masks.append(mask.astype(bool))
        
        return masks
    
    def _masks_to_instances(self, masks: List[np.ndarray], classes: np.ndarray, h: int, w: int) -> Instances:
        """
        å°†maskåˆ—è¡¨è½¬æ¢å›Instanceså¯¹è±¡
        
        ğŸ”§ å…³é”®ä¿®å¤ï¼šæŒ‰maské¢ç§¯æ’åºï¼Œä¸Format._format_segmentsä¿æŒä¸€è‡´ï¼
        è¿™æ ·Formatåœ¨é‡æ–°æ’åºæ—¶ï¼Œé¡ºåºä¸ä¼šæ”¹å˜ï¼Œclså’Œinstanceså°±èƒ½æ­£ç¡®å¯¹åº”
        """
        from ultralytics.utils.ops import resample_segments
        
        segments = []
        bboxes = []
        areas = []  # ğŸ”§ æ–°å¢ï¼šè®°å½•æ¯ä¸ªmaskçš„é¢ç§¯
        
        for mask in masks:
            # æå–è½®å»“
            contours, _ = cv2.findContours(
                mask.astype(np.uint8),
                cv2.RETR_EXTERNAL,
                cv2.CHAIN_APPROX_SIMPLE
            )
            
            if len(contours) > 0:
                # ä½¿ç”¨æœ€å¤§çš„è½®å»“
                contour = max(contours, key=cv2.contourArea)
                segment = contour.reshape(-1, 2).astype(np.float32)
                segments.append(segment)
                
                # è®¡ç®—bbox
                x1, y1 = segment.min(axis=0)
                x2, y2 = segment.max(axis=0)
                bboxes.append([x1, y1, x2, y2])
                
                # ğŸ”§ è®¡ç®—é¢ç§¯ï¼ˆä¸polygons2masks_overlapä¿æŒä¸€è‡´ï¼‰
                areas.append(mask.sum())
        
        if len(segments) == 0:
            # è¿”å›ç©ºçš„Instancesï¼Œæ ¼å¼ä¸dataset.pyä¿æŒä¸€è‡´
            return Instances(
                bboxes=np.empty((0, 4)),
                segments=np.zeros((0, 1000, 2), dtype=np.float32),
                bbox_format='xyxy',
                normalized=False
            )
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šæŒ‰é¢ç§¯ä»å¤§åˆ°å°æ’åºï¼ˆä¸Format._format_segmentsä¸€è‡´ï¼‰
        areas = np.array(areas)
        sorted_idx = np.argsort(-areas)  # ä»å¤§åˆ°å°
        
        segments = [segments[i] for i in sorted_idx]
        bboxes = [bboxes[i] for i in sorted_idx]
        classes = classes[sorted_idx]  # åŒæ­¥æ’åºclasses
        
        # Resample segments to 1000 points (ä¸dataset.pyä¿æŒä¸€è‡´)
        segments_resampled = resample_segments(segments, n=1000)
        segments_array = np.stack(segments_resampled, axis=0)  # Shape: (N, 1000, 2)
        
        instances = Instances(
            bboxes=np.array(bboxes),
            segments=segments_array,
            bbox_format='xyxy',
            normalized=False  # æˆ‘ä»¬çš„åæ ‡æ˜¯åƒç´ åæ ‡ï¼Œæœªå½’ä¸€åŒ–
        )
        instances.cls = classes
        
        return instances
    
    def _transform_instance(self, instance: Dict[str, Any], scale_range: Tuple[float, float]) -> Dict[str, Any]:
        """
        å¯¹å®ä¾‹åº”ç”¨éšæœºå˜æ¢ï¼ˆç¼©æ”¾ã€æ—‹è½¬ç­‰ï¼‰
        
        Args:
            instance: å®ä¾‹å­—å…¸
            scale_range: ç¼©æ”¾èŒƒå›´
            
        Returns:
            å˜æ¢åçš„å®ä¾‹
        """
        img = instance['image'].copy()
        mask = instance['mask'].copy()
        
        # éšæœºç¼©æ”¾
        scale = random.uniform(scale_range[0], scale_range[1])
        h, w = img.shape[:2]
        new_h, new_w = int(h * scale), int(w * scale)
        
        if new_h > 0 and new_w > 0:
            img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            mask = cv2.resize(mask.astype(np.uint8), (new_w, new_h), interpolation=cv2.INTER_NEAREST).astype(bool)
        
        # å¯ä»¥æ·»åŠ æ›´å¤šå˜æ¢ï¼šæ—‹è½¬ã€ç¿»è½¬ç­‰
        # éšæœºæ°´å¹³ç¿»è½¬
        if random.random() < 0.5:
            img = cv2.flip(img, 1)
            mask = cv2.flip(mask.astype(np.uint8), 1).astype(bool)
        
        return {
            'image': img,
            'mask': mask,
            'class_id': instance['class_id']
        }
    
    def _get_paste_position(self, instance: Dict[str, Any], img_h: int, img_w: int) -> Tuple[int, int]:
        """
        è·å–ç²˜è´´ä½ç½®ï¼ˆéšæœºï¼‰
        
        Args:
            instance: å®ä¾‹å­—å…¸
            img_h: ç›®æ ‡å›¾åƒé«˜åº¦
            img_w: ç›®æ ‡å›¾åƒå®½åº¦
            
        Returns:
            (x, y) å·¦ä¸Šè§’åæ ‡
        """
        inst_h, inst_w = instance['mask'].shape
        
        # ç¡®ä¿ç²˜è´´åå®ä¾‹å®Œå…¨åœ¨å›¾åƒå†…
        max_x = max(0, img_w - inst_w)
        max_y = max(0, img_h - inst_h)
        
        x = random.randint(0, max_x) if max_x > 0 else 0
        y = random.randint(0, max_y) if max_y > 0 else 0
        
        return x, y
    
    def _handle_occlusion(self, existing_masks: List[np.ndarray], new_mask: np.ndarray) -> List[np.ndarray]:
        """
        å¤„ç†æ–°ç²˜è´´maskå¯¹ç°æœ‰masksçš„é®æŒ¡
        
        æ ¸å¿ƒé€»è¾‘ï¼š
        1. å¯¹æ¯ä¸ªç°æœ‰maskï¼Œè®¡ç®—ä¸new_maskçš„äº¤é›†
        2. å¦‚æœæœ‰äº¤é›†ï¼Œä»ç°æœ‰maskä¸­å‡å»äº¤é›†éƒ¨åˆ†
        3. å¦‚æœå‡å»åé¢ç§¯å¤ªå°ï¼Œåˆ é™¤è¯¥mask
        
        Args:
            existing_masks: ç°æœ‰maskåˆ—è¡¨
            new_mask: æ–°ç²˜è´´çš„mask
            
        Returns:
            æ›´æ–°åçš„maskåˆ—è¡¨
        """
        updated_masks = []
        
        for mask in existing_masks:
            # è®¡ç®—äº¤é›†
            intersection = mask & new_mask
            
            if intersection.sum() > 0:
                # æœ‰é®æŒ¡ï¼Œæ›´æ–°mask
                updated_mask = mask & ~new_mask
                
                # æ£€æŸ¥å‰©ä½™é¢ç§¯
                if updated_mask.sum() >= self.min_area_threshold:
                    updated_masks.append(updated_mask)
                # å¦åˆ™è¯¥maskè¢«å®Œå…¨é®æŒ¡ï¼Œä¸¢å¼ƒ
            else:
                # æ— é®æŒ¡ï¼Œä¿ç•™åŸmask
                updated_masks.append(mask)
        
        return updated_masks
    
    def _handle_occlusion_with_classes(self, existing_items: List[Tuple[np.ndarray, int]], new_mask: np.ndarray) -> List[Tuple[np.ndarray, int]]:
        """
        å¤„ç†æ–°ç²˜è´´maskå¯¹ç°æœ‰itemsçš„é®æŒ¡ï¼ŒåŒæ—¶ä¿æŒmaskå’Œclass_idçš„åŒæ­¥
        
        Args:
            existing_items: ç°æœ‰itemsåˆ—è¡¨ï¼Œæ¯ä¸ªitemæ˜¯(mask, class_id)çš„å…ƒç»„
            new_mask: æ–°ç²˜è´´çš„mask
            
        Returns:
            æ›´æ–°åçš„itemsåˆ—è¡¨ï¼Œä¿è¯maskå’Œclass_idä¸€ä¸€å¯¹åº”
        """
        updated_items = []
        
        for mask, class_id in existing_items:
            # è®¡ç®—äº¤é›†
            intersection = mask & new_mask
            
            if intersection.sum() > 0:
                # æœ‰é®æŒ¡ï¼Œæ›´æ–°mask
                updated_mask = mask & ~new_mask
                
                # æ£€æŸ¥å‰©ä½™é¢ç§¯
                if updated_mask.sum() >= self.min_area_threshold:
                    updated_items.append((updated_mask, class_id))  # ä¿æŒclass_idä¸å˜
                # å¦åˆ™è¯¥maskè¢«å®Œå…¨é®æŒ¡ï¼Œä¸¢å¼ƒï¼ˆclass_idä¹Ÿä¸€èµ·ä¸¢å¼ƒï¼‰
            else:
                # æ— é®æŒ¡ï¼Œä¿ç•™åŸitem
                updated_items.append((mask, class_id))
        
        return updated_items
    
    def _blend_paste(
        self,
        target_img: np.ndarray,
        source_img: np.ndarray,
        paste_mask: np.ndarray,
        paste_x: int,
        paste_y: int
    ) -> np.ndarray:
        """
        å¸¦è¾¹ç¼˜ç¾½åŒ–çš„ç²˜è´´
        
        Args:
            target_img: ç›®æ ‡å›¾åƒ
            source_img: æºå®ä¾‹å›¾åƒ
            paste_mask: ç²˜è´´mask
            paste_x, paste_y: ç²˜è´´ä½ç½®
            
        Returns:
            æ··åˆåçš„å›¾åƒ
        """
        # æå–ç²˜è´´åŒºåŸŸçš„mask
        h, w = target_img.shape[:2]
        inst_h, inst_w = source_img.shape[:2]
        
        y_end = min(paste_y + inst_h, h)
        x_end = min(paste_x + inst_w, w)
        
        # å¯¹maskè¾¹ç¼˜è¿›è¡Œé«˜æ–¯æ¨¡ç³Š
        mask_region = paste_mask[paste_y:y_end, paste_x:x_end].astype(np.uint8)
        blurred_mask = cv2.GaussianBlur(mask_region * 255, (self.blend_kernel, self.blend_kernel), 0) / 255.0
        
        # Alphaæ··åˆ
        inst_h_actual = y_end - paste_y
        inst_w_actual = x_end - paste_x
        
        for c in range(3):
            target_img[paste_y:y_end, paste_x:x_end, c] = (
                blurred_mask * source_img[:inst_h_actual, :inst_w_actual, c] +
                (1 - blurred_mask) * target_img[paste_y:y_end, paste_x:x_end, c]
            )
        
        return target_img


def build_instance_pool_from_dataset(dataset, max_images: int = 200, max_pool_size: int = 1000, sample_strategy: str = 'uniform') -> InstancePool:
    """
    ä¾¿æ·å‡½æ•°ï¼šä»æ•°æ®é›†æ„å»ºå®ä¾‹æ± 
    
    Args:
        dataset: YOLOæ•°æ®é›†å¯¹è±¡
        max_images: æœ€å¤šä½¿ç”¨å¤šå°‘å¼ å›¾åƒ
        max_pool_size: å®ä¾‹æ± æœ€å¤§å®¹é‡
        sample_strategy: é‡‡æ ·ç­–ç•¥ ('uniform'=å‡åŒ€, 'random'=éšæœº, 'sequential'=é¡ºåº)
        
    Returns:
        æ„å»ºå¥½çš„å®ä¾‹æ± 
    """
    pool = InstancePool(max_size=max_pool_size)
    pool.build_from_dataset(dataset, max_images=max_images, verbose=True, sample_strategy=sample_strategy)
    return pool

